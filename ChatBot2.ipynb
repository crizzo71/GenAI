{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==3.0.0\n",
      "  Using cached transformers-3.0.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from transformers==3.0.0) (1.26.0)\n",
      "Collecting tokenizers==0.8.0-rc4 (from transformers==3.0.0)\n",
      "  Using cached tokenizers-0.8.0rc4.tar.gz (96 kB)\n",
      "  Installing build dependencies ... \u001b[?done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from transformers==3.0.0) (24.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers==3.0.0) (3.13.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers==3.0.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==3.0.0) (4.66.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==3.0.0) (2024.9.11)\n",
      "Requirement already satisfied: sentencepiece in /opt/anaconda3/lib/python3.12/site-packages (from transformers==3.0.0) (0.2.0)\n",
      "Collecting sacremoses (from transformers==3.0.0)\n",
      "  Using cached sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==3.0.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==3.0.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==3.0.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==3.0.0) (2025.1.31)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from sacremoses->transformers==3.0.0) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from sacremoses->transformers==3.0.0) (1.4.2)\n",
      "Using cached transformers-3.0.0-py3-none-any.whl (754 kB)\n",
      "Using cached sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "Building wheels for collected packages: tokenizers\n",
      "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[59 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/xv/kndpyv2j2fj7z3v04mv005qh0000gn/T/pip-build-env-2aob87t3/overlay/lib/python3.12/site-packages/setuptools/dist.py:334: InformationOnly: Normalizing '0.8.0.rc4' to '0.8.0rc4'\n",
      "  \u001b[31m   \u001b[0m   self.metadata.version = self._normalize_version(self.metadata.version)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/xv/kndpyv2j2fj7z3v04mv005qh0000gn/T/pip-build-env-2aob87t3/overlay/lib/python3.12/site-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         License :: OSI Approved :: Apache Software License\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   self._finalize_license_expression()\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-312/tokenizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/__init__.py -> build/lib.macosx-11.1-arm64-cpython-312/tokenizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-312/tokenizers/models\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/models/__init__.py -> build/lib.macosx-11.1-arm64-cpython-312/tokenizers/models\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-312/tokenizers/decoders\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/decoders/__init__.py -> build/lib.macosx-11.1-arm64-cpython-312/tokenizers/decoders\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-312/tokenizers/normalizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/normalizers/__init__.py -> build/lib.macosx-11.1-arm64-cpython-312/tokenizers/normalizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-312/tokenizers/pre_tokenizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/pre_tokenizers/__init__.py -> build/lib.macosx-11.1-arm64-cpython-312/tokenizers/pre_tokenizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-312/tokenizers/processors\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/processors/__init__.py -> build/lib.macosx-11.1-arm64-cpython-312/tokenizers/processors\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-312/tokenizers/trainers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/trainers/__init__.py -> build/lib.macosx-11.1-arm64-cpython-312/tokenizers/trainers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-312/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/byte_level_bpe.py -> build/lib.macosx-11.1-arm64-cpython-312/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/sentencepiece_bpe.py -> build/lib.macosx-11.1-arm64-cpython-312/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/base_tokenizer.py -> build/lib.macosx-11.1-arm64-cpython-312/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/__init__.py -> build/lib.macosx-11.1-arm64-cpython-312/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/char_level_bpe.py -> build/lib.macosx-11.1-arm64-cpython-312/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/implementations/bert_wordpiece.py -> build/lib.macosx-11.1-arm64-cpython-312/tokenizers/implementations\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/__init__.pyi -> build/lib.macosx-11.1-arm64-cpython-312/tokenizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/models/__init__.pyi -> build/lib.macosx-11.1-arm64-cpython-312/tokenizers/models\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/decoders/__init__.pyi -> build/lib.macosx-11.1-arm64-cpython-312/tokenizers/decoders\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/normalizers/__init__.pyi -> build/lib.macosx-11.1-arm64-cpython-312/tokenizers/normalizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/pre_tokenizers/__init__.pyi -> build/lib.macosx-11.1-arm64-cpython-312/tokenizers/pre_tokenizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/processors/__init__.pyi -> build/lib.macosx-11.1-arm64-cpython-312/tokenizers/processors\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/trainers/__init__.pyi -> build/lib.macosx-11.1-arm64-cpython-312/tokenizers/trainers\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m running build_rust\n",
      "  \u001b[31m   \u001b[0m error: can't find Rust compiler\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m To update pip, run:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     pip install --upgrade pip\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m and then retry package installation.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25hFailed to build tokenizers\n",
      "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tokenizers)\u001b[0m\u001b[31m\n",
      "Requirement already satisfied: sentencepiece in /opt/anaconda3/lib/python3.12/site-packages (0.2.0)\n",
      "Collecting torch==2.2\n",
      "  Using cached torch-2.2.0-cp312-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2) (1.13.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch==2.2) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->torch==2.2) (1.3.0)\n",
      "Using cached torch-2.2.0-cp312-none-macosx_11_0_arm64.whl (59.7 MB)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.2\n",
      "    Uninstalling torch-2.2.2:\n",
      "      Successfully uninstalled torch-2.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.17.2 requires torch==2.2.2, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.2.0\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow.2 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[31mERROR: No matching distribution found for tensorflow.2\u001b[0m\u001b[31m\n",
      "Requirement already satisfied: torchtext==0.17.2 in /opt/anaconda3/lib/python3.12/site-packages (0.17.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from torchtext==0.17.2) (4.66.5)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from torchtext==0.17.2) (2.32.3)\n",
      "Collecting torch==2.2.2 (from torchtext==0.17.2)\n",
      "  Using cached torch-2.2.2-cp312-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchtext==0.17.2) (1.26.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (1.13.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->torchtext==0.17.2) (2024.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchtext==0.17.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchtext==0.17.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchtext==0.17.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torchtext==0.17.2) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch==2.2.2->torchtext==0.17.2) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->torch==2.2.2->torchtext==0.17.2) (1.3.0)\n",
      "Using cached torch-2.2.2-cp312-none-macosx_11_0_arm64.whl (59.7 MB)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.0\n",
      "    Uninstalling torch-2.2.0:\n",
      "      Successfully uninstalled torch-2.2.0\n",
      "Successfully installed torch-2.2.2\n",
      "Requirement already satisfied: numpy==1.26 in /opt/anaconda3/lib/python3.12/site-packages (1.26.0)\n"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "!pip install transformers==3.0.0\n",
    "!pip install -qq tensorflow\n",
    "!pip install sentencepiece\n",
    "!pip install torch==2.2\n",
    "!pip install -qq tensorflow.2\n",
    "!pip install torchtext==0.17.2\n",
    "!pip install numpy==1.26\n",
    "#!pip install --upgrade numpy transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AutoModelForSeq2SeqLM' from 'transformers' (/opt/anaconda3/envs/GenAi/lib/python3.12/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Tools for tranformer \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSeq2SeqLM \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Selecting the model. You will be using \"facebook/blenderbot-400M-distill\" in this example.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/blenderbot-400M-distill\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'AutoModelForSeq2SeqLM' from 'transformers' (/opt/anaconda3/envs/GenAi/lib/python3.12/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "#Tools for tranformer \n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM \n",
    "\n",
    "# Selecting the model. You will be using \"facebook/blenderbot-400M-distill\" in this example.\n",
    "model_name = \"facebook/blenderbot-400M-distill\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Define the chat function\n",
    "def chat_with_bot():\n",
    "    while True:\n",
    "        # Get user input\n",
    "        input_text = input(\"You: \")\n",
    "\n",
    "        # Exit conditions\n",
    "        if input_text.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Tokenize input and generate response\n",
    "        inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "        outputs = model.generate(inputs, max_new_tokens=150) \n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "        # Display bot's response\n",
    "        print(\"Chatbot:\", response)\n",
    "\n",
    "# Start chatting\n",
    "chat_with_bot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try with new model \n",
    "import sentencepiece\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "model_name = \"google/flan-t5-small\" #here the model name can be changed as you like.\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's chat with another bot\n",
    "def chat_with_another_bot():\n",
    "    while True:\n",
    "        # Get user input\n",
    "        input_text = input(\"You: \")\n",
    "\n",
    "        # Exit conditions\n",
    "        if input_text.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Tokenize input and generate response\n",
    "        inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "        outputs = model.generate(inputs, max_new_tokens=150) \n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "        \n",
    "        # Display bot's response\n",
    "        print(\"Chatbot:\", response)\n",
    "\n",
    "# Start chatting\n",
    "chat_with_another_bot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
